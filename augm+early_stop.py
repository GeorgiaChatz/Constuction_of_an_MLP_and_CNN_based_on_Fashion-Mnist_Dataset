# -*- coding: utf-8 -*-
"""augm+early stop.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fCmJysEQiRGlFJfWDfQ0LwvT5exWZXE6
"""

#TensorFlow and tf.keras
import tensorflow as tf
from tensorflow import keras

# Helper libraries
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten,BatchNormalization,MaxPooling2D,Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.optimizers import SGD
from tensorflow.keras import regularizers
from keras import callbacks
from sklearn.model_selection import train_test_split
from keras.preprocessing.image import ImageDataGenerator


NUM_EPOCHS = 30
BS = 128
INIT_LR=1e-2
IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS, NUM_CLASSES = 28, 28, 1, 10
l2=regularizers.l2(0.01)


fashion_mnist = keras.datasets.fashion_mnist
(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()
print(' - X_train.shape = {}, Y_train.shape = {}'.format(X_train.shape, Y_train.shape))
print(' - X_test.shape = {}, Y_test.shape = {}'.format(X_test.shape, Y_test.shape))


# keep an non pre-processed copy of X_test/y_test for visualization
test_images, test_labels = X_test.copy(), Y_test.copy()
X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.2, random_state=13)

X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0
X_val = X_val.astype('float32')/ 255.0



X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))
X_val = np.reshape(X_val, (X_val.shape[0], X_val.shape[1], X_val.shape[2], 1))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2], 1))


print('After preprocessing:')
print(' - X_train.shape = {}, y_train.shape = {}'.format(X_train.shape, Y_train.shape))
print(' - X_val.shape = {}, y_val.shape = {}'.format(X_val.shape, Y_val.shape))
print(' - X_test.shape = {}, y_test.shape = {}'.format(X_test.shape, Y_test.shape))
print(' - test_images.shape = {}, test_labels.shape = {}'.format(test_images.shape,
test_labels.shape))


model = Sequential([
        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same',kernel_regularizer=l2,
               input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS)),
        BatchNormalization(),
        Conv2D(64, kernel_size=(3, 3), activation='relu',kernel_regularizer=l2 ),
        BatchNormalization(),
        MaxPooling2D(pool_size=(2, 2)),
        Dropout(0.20),

        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same',kernel_regularizer=l2 ),
        BatchNormalization(),
        Conv2D(128, kernel_size=(3, 3), activation='relu',kernel_regularizer=l2),
        BatchNormalization(),
        MaxPooling2D(pool_size=(2, 2)),
        Dropout(0.30),

        Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same',kernel_regularizer=l2),
        BatchNormalization(),
        Conv2D(256, kernel_size=(3, 3), activation='relu',kernel_regularizer=l2),
        BatchNormalization(),
        MaxPooling2D(pool_size=(2, 2)),
        Dropout(0.40),

        Flatten(),

        Dense(1024, activation='relu',kernel_regularizer=l2),
        Dropout(0.30),

        Dense(512, activation='relu',kernel_regularizer=l2),
        Dropout(0.40),

        Dense(NUM_CLASSES, activation='softmax')
    ])

cnn_models = [model]

for model in cnn_models:
    model.summary()


#early stopping
eary_stopping = callbacks.EarlyStopping(
    monitor='val_loss',
    min_delta=0,
    patience=7,
    verbose=1,
    mode='auto')

callbacks = [eary_stopping]

#Data Augmentation 
datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
        zoom_range = 0.01, # Randomly zoom image
        width_shift_range=0.03,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=0.03,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=False,  # randomly flip images
        vertical_flip=False)  # randomly flip images


adam = Adam(lr=0.0001, decay=1e-6)
# optimizer = RMSprop(lr = 0.001, rho=0.9, epsilon=1e-08, decay=0.0)
#opt = SGD(lr=INIT_LR, momentum=0.9, decay=INIT_LR / NUM_EPOCHS)


history_dict = {} 

for model in cnn_models:
    model.compile(optimizer=adam, loss='sparse_categorical_crossentropy',metrics=['accuracy'])
    #model.fit(X_train, Y_train, epochs=NUM_EPOCHS,batch_size=BS, validation_data=(X_val, Y_val))
    history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=BS),
                                  epochs = NUM_EPOCHS, validation_data = (X_val,Y_val), callbacks=callbacks, 
                                  verbose = 2, steps_per_epoch=X_train.shape[0] // BS)
    history_dict[model.name] = history

    print("Evaluating... ")
    print('Training data:', flush=True)
    loss, acc = model.evaluate(X_train, Y_train, verbose=1)
    print("  Training : loss %.3f - acc %.3f" % (loss, acc))
    print('Cross-validation data:', flush=True)
    loss, acc = model.evaluate(X_val, Y_val, verbose=1)
    print("  Cross-val: loss %.3f - acc %.3f" % (loss, acc))
    print('Test data:', flush=True)
    loss, acc = model.evaluate(X_test, Y_test, verbose=1)
    print("  Testing  : loss %.3f - acc %.3f" % (loss, acc))


fig, (ax1, ax2, ax3, ax4) = plt.subplots(4, figsize=(8, 16))

for history in history_dict:
    train_acc = history_dict[history].history['acc']
    train_loss = history_dict[history].history['loss']
    val_acc = history_dict[history].history['val_acc']
    val_loss = history_dict[history].history['val_loss']
    ax1.plot(val_acc, label=history)
    ax2.plot(val_loss, label=history)
    ax3.plot(train_acc, label=history)
    ax4.plot(train_loss, label=history)
    
ax1.set_ylabel('validation accuracy')
ax1.set_xlabel('epochs')
ax2.set_ylabel('validation loss')
ax2.set_xlabel('epochs')
ax3.set_ylabel('train accuracy')
ax3.set_xlabel('epochs')
ax4.set_ylabel('train loss')
ax4.set_xlabel('epochs')
ax1.legend()
ax2.legend()
ax3.legend()
ax4.legend()
plt.show()